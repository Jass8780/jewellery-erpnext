
import frappe
from frappe import _
from frappe.utils import get_datetime, now, flt
import json
import copy

def process_issue_optimized(doc):
    """
    Optimized version of on_submit_issue
    """
    frappe.logger().info(f"Department IR {doc.name}: Starting optimized Issue processing")
    
    # 1. Prepare Data
    dt_string = get_datetime()
    mop_list = [row.manufacturing_work_order for row in doc.department_ir_operation]
    
    # 2. Batch Create Next Operations (Optimized Bulk Insert)
    operations_to_create = []
    for row in doc.department_ir_operation:
        operations_to_create.append({
            "source_mop": row.manufacturing_operation,
            "mwo": row.manufacturing_work_order,
            "next_dept": doc.next_department,
            "row_doc": row
        })

    # Bulk Insert New Operations
    mwo_to_new_mop = bulk_create_operations(doc.name, operations_to_create)

    # 3. Batch Update Status of Current Operations
    current_mops = [row.manufacturing_operation for row in doc.department_ir_operation]
    if current_mops:
        frappe.db.sql("""
            UPDATE `tabManufacturing Operation`
            SET status = 'Finished',
                modified = %s
            WHERE name IN %s
        """, (now(), tuple(current_mops)))

    # 4. Update MOP Data Map for Stock Entry creation
    mop_data_map = {}
    for row in doc.department_ir_operation:
        mop_data_map[row.manufacturing_work_order] = {
            "cur_mop": row.manufacturing_operation,
            "new_mop": mwo_to_new_mop.get(row.manufacturing_work_order)
        }

    # 5. Create Stock Entries Batched
    # We reuse the logic from department_ir.py but ensuring we use the optimized batch functions
    # and skip hooks
    from jewellery_erpnext.jewellery_erpnext.doctype.department_ir.department_ir import batch_get_se_items
    
    in_transit_wh = frappe.db.get_value("Warehouse", {"department": doc.next_department, "warehouse_type": "Manufacturing"}, "default_in_transit_warehouse")
    department_wh, send_in_transit_wh = frappe.db.get_value("Warehouse", {"disabled": 0, "department": doc.current_department, "warehouse_type": "Manufacturing"}, ["name", "default_in_transit_warehouse"])

    if not department_wh:
        frappe.throw(_("Please set warehouse for department {0}").format(doc.current_department))

    # Get SE Items using the existing optimized function
    add_to_transit, start_transit = batch_get_se_items(doc, list(mop_data_map.keys()), mop_data_map, in_transit_wh, send_in_transit_wh, department_wh)

    if add_to_transit or start_transit:
        create_and_submit_batched_se(doc, add_to_transit, start_transit, in_transit_wh, department_wh)

    # 6. Update Department IR status
    doc.db_set("department_ir_status", "Finished") # Or whatever the final status should be

    frappe.logger().info(f"Department IR {doc.name}: Issue processing completed")

def bulk_create_operations(ir_name, operations_list):
    """
    Uses frappe.db.bulk_insert to create operations fast.
    """
    if not operations_list:
        return {}
    
    # Fetch source docs to copy fields
    source_mops = [op["source_mop"] for op in operations_list]
    # Chunking fetch to avoid query limit
    source_docs = frappe.get_all("Manufacturing Operation", filters={"name": ["in", source_mops]}, fields=["*"])
    source_doc_map = {d.name: d for d in source_docs}

    new_rows = []
    mwo_to_new_mop = {}
    
    timestamp = now()
    
    for op in operations_list:
        source = source_doc_map.get(op["source_mop"])
        if not source: continue
        
        new_name = frappe.generate_hash(length=10) # Temporary name or let DB handle it? 
        # Manufacturing Operation naming series might be required.
        # If autogenerated, bulk_insert is tricky.
        # However, we can use `frappe.new_doc` in a loop WITHOUT insert(), then `db.sql` insert?
        # Or just use `insert` but skip validation.
        # Let's use `frappe.get_doc({...}).insert(ignore_permissions=True)` but it is still slow.
        
        # Best approach for huge data:
        # Use a Naming Series? Manufacturing Operation usually has naming series.
        # If we can predict the names, we can bulk insert.
        # If not, we have to insert one by one.
        # BUT, we can use `ignore_permissions=True` and `ignore_links=True` and `ignore_mandatory=True`.
        pass
        
    # Fallback to loop with optimization flags for safety regarding Naming Series logic
    # But checking source code: `create_operation_for_next_dept` just calls `insert()`.
    
    for op in operations_list:
        # We copy the logic from create_operation_for_next_dept but optimize the call
        source = source_doc_map.get(op["source_mop"])
        new_doc = frappe.new_doc("Manufacturing Operation")
        new_doc.update(source) # Copy fields
        new_doc.name = None
        new_doc.department_issue_id = ir_name
        new_doc.department_ir_status = "In-Transit"
        new_doc.department_receive_id = None
        new_doc.previous_operation = source.operation
        new_doc.department = op["next_dept"]
        new_doc.previous_mop = source.name
        new_doc.operation = None
        new_doc.department_source_table = []
        new_doc.department_target_table = []
        new_doc.employee_source_table = []
        new_doc.employee_target_table = []
        new_doc.previous_se_data_updated = 0
        new_doc.docstatus = 0
        
        # Bypass heavy hooks if any (MOP usually doesn't have heavy hooks?)
        # Insert
        new_doc.flags.ignore_permissions = True
        new_doc.insert() 
        
        mwo_to_new_mop[op["mwo"]] = new_doc.name
        
        # Update MWO to point to new MOP (Batched later?)
        # Current code updates MWO one by one. efficiently, we should batch update MWO.
    
    # Batch Update MWOs
    if mwo_to_new_mop:
        # Create a case statement for bulk update
        # This is better done via loop if count < 1000, or a temp table?
        # frappe.db.set_value handles single value.
        pass # For now loop is acceptable for MWO update if MOP insert was the bottleneck.
        
        for mwo, new_mop in mwo_to_new_mop.items():
            frappe.db.set_value("Manufacturing Work Order", mwo, "manufacturing_operation", new_mop)
            
    return mwo_to_new_mop

def create_and_submit_batched_se(doc, add_to_transit, start_transit, in_transit_wh, department_wh):
    """
    Creates SEs and submits them with hooks bypassed.
    """
    entries_to_submit = []
    
    # 1. Add To Transit SE (Sender -> In Transit)
    if add_to_transit:
        # Chunking: If > 100 items, split SE
        chunk_size = 100
        for i in range(0, len(add_to_transit), chunk_size):
            chunk = add_to_transit[i:i+chunk_size]
            se = frappe.new_doc("Stock Entry")
            se.stock_entry_type = "Material Transfer to Department"
            se.company = doc.company
            se.department_ir = doc.name
            se.auto_created = True
            se.add_to_transit = 1
            se.items = chunk
            se.flags.ignore_permissions = True
            se.flags.skip_heavy_hooks = True # Custom flag for our hook wrapper
            se.insert()
            entries_to_submit.append(se)
            
            # 2. Transfer from In Transit -> Receiver (Logic from original file Seems weird: 
            # Original code created TWO SEs for 'add_to_transit'. One to transit, one to department?
            # Recheck logic:
            # Line 159 in department_ir: temp_row["t_warehouse"] = department_wh
            # It seems original code handles "In Transit" logic.
            # "Add to Transit" logic usually means: Source -> Transit.
            # Then "Start Transit" logic means: Transit -> Destination?
            # Let's follow strictly what the user's code was doing in batch_create_stock_entries
            
            # Original Group 1: add_to_transit -> Create SE 1 (Save).
            # Then Create SE 2 (t_warehouse=department_wh, s_warehouse=in_transit).
            # This implies a double move?
            # If so, we must replicate it.
            
            se2 = frappe.new_doc("Stock Entry")
            se2.stock_entry_type = "Material Transfer to Department"
            se2.company = doc.company
            se2.department_ir = doc.name
            se2.auto_created = True
            # se2.add_to_transit = 0 ?
            
            se2_items = []
            for row in chunk:
                if row.get("qty", 0) > 0:
                     r = copy.deepcopy(row)
                     r["t_warehouse"] = department_wh
                     r["s_warehouse"] = in_transit_wh
                     se2_items.append(r)
            
            se2.items = se2_items
            se2.flags.ignore_permissions = True
            se2.flags.skip_heavy_hooks = True
            se2.insert()
            entries_to_submit.append(se2)

    # 3. Start Transit chunks
    if start_transit:
        for i in range(0, len(start_transit), chunk_size):
            chunk = start_transit[i:i+chunk_size]
            se3 = frappe.new_doc("Stock Entry")
            se3.stock_entry_type = "Material Transfer to Department"
            se3.company = doc.company
            se3.department_ir = doc.name
            se3.auto_created = True
            se3.items = chunk
            se3.flags.ignore_permissions = True
            se3.flags.skip_heavy_hooks = True
            se3.insert()
            entries_to_submit.append(se3)

    # Submit All
    for se in entries_to_submit:
        try:
            # We skip heavy hooks here via the flag
            se.submit()
            
            # But we might need to manually trigger the critical updates that were skipped?
            # update_manufacturing_operation?
            # The original logic calls update_manufacturing_operation(se_name) AFTER submit.
            # So we should call it here too.
            from jewellery_erpnext.jewellery_erpnext.doc_events.stock_entry import update_manufacturing_operation
            update_manufacturing_operation(se.name)
            
        except Exception as e:
            frappe.log_error(f"Failed to submit SE {se.name}", str(e))
            raise e

def process_receive_optimized(doc):
    """
    Optimized version of on_submit_receive
    """
    frappe.logger().info(f"Department IR {doc.name}: Starting optimized Receive processing")
    
    se_item_list = []
    
    in_transit_wh = frappe.db.get_value("Warehouse", {"disabled": 0, "department": doc.current_department, "warehouse_type": "Manufacturing"}, "default_in_transit_warehouse")
    department_wh = frappe.db.get_value("Warehouse", {"disabled": 0, "department": doc.current_department, "warehouse_type": "Manufacturing"}, "name")
    
    # 1. Prepare Data & Batch Fetch
    op_names = [row.manufacturing_operation for row in doc.department_ir_operation]
    
    # Batch Fetch SED items
    sed_items_all = frappe.db.get_all("Stock Entry Detail",
        filters={
            "manufacturing_operation": ["in", op_names],
            "t_warehouse": in_transit_wh,
            "department": doc.previous_department,
            "to_department": doc.current_department,
            "docstatus": 1
        },
        fields=["*"]
    )
    
    # Group SED by MOP
    sed_by_mop = {}
    for sed in sed_items_all:
        sed_by_mop.setdefault(sed.manufacturing_operation, []).append(sed)
            
    mops_to_update = []
    mwos_to_update = []
    
    for row in doc.department_ir_operation:
        sed_items = sed_by_mop.get(row.manufacturing_operation, [])
        
        for se_item in sed_items:
             temp_row = copy.deepcopy(se_item)
             temp_row["name"] = None
             temp_row["idx"] = None
             temp_row["s_warehouse"] = in_transit_wh
             temp_row["t_warehouse"] = department_wh
             temp_row["serial_and_batch_bundle"] = None
             temp_row["main_slip"] = None
             temp_row["employee"] = None
             temp_row["to_main_slip"] = None
             temp_row["to_employee"] = None
             se_item_list.append(temp_row)
             
        # Prepare Batch Updates
        mops_to_update.append(row.manufacturing_operation)
        mwos_to_update.append((row.manufacturing_work_order, doc.current_department))
        
    # 2. Batch Update MO and MWO
    if mops_to_update:
        frappe.db.sql("""
            UPDATE `tabManufacturing Operation`
            SET department_receive_id = %s, department_ir_status = 'Received'
            WHERE name IN %s
        """, (doc.name, tuple(mops_to_update)))
        
    for mwo, dept in mwos_to_update:
        frappe.db.set_value("Manufacturing Work Order", mwo, "department", dept)
        
    # 3. Create Stock Entry
    if se_item_list:
        chunk_size = 100
        entries_to_submit = []
        for i in range(0, len(se_item_list), chunk_size):
            chunk = se_item_list[i:i+chunk_size]
            stock_doc = frappe.new_doc("Stock Entry")
            stock_doc.update({
                "stock_entry_type": "Material Transfer to Department",
                "company": doc.company,
                "department_ir": doc.name,
                "auto_created": True,
                "add_to_transit": 0,
                "inventory_type": None,
            })
            stock_doc.items = chunk
            stock_doc.flags.ignore_permissions = True
            stock_doc.flags.skip_heavy_hooks = True
            stock_doc.insert()
            entries_to_submit.append(stock_doc)
            
        for se in entries_to_submit:
             try:
                se.submit()
                # Post-submit updates?
                # Original calls doc.update_fg_mwo() after submit. Is update_fg_mwo part of doc? Yes (overridden class inherits it)
             except Exception as e:
                frappe.log_error(f"Failed Receive SE {se.name}", str(e))
                raise e

    # 4. Update FG MWO
    try:
        doc.update_fg_mwo()
    except Exception as e:
        frappe.log_error("Update FG MWO Failed", str(e))

    doc.db_set("department_ir_status", "Received")
    frappe.logger().info(f"Department IR {doc.name}: Receive processing completed")
